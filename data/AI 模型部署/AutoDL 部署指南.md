# AutoDL AI æ¨¡å‹éƒ¨ç½²è¯¦ç»†æŒ‡å—

> **é€‚ç”¨äººç¾¤**ï¼šéœ€è¦åœ¨ AutoDL ä¸Šéƒ¨ç½²ç‰™ç§‘ä¿®å¤ AI æ¨¡å‹çš„æ¯•ä¸šç”Ÿ
> **é¢„è®¡è€—æ—¶**ï¼š2-4 å°æ—¶ï¼ˆé¦–æ¬¡éƒ¨ç½²ï¼‰
> **éš¾åº¦ç­‰çº§**ï¼šâ­â­â­â˜†â˜†
> **å‰ç½®æ¡ä»¶**ï¼šå·²å®Œæˆæ¨¡å‹å¾®è°ƒè®­ç»ƒï¼Œæ‹¥æœ‰åˆå¹¶åçš„æ¨¡å‹æƒé‡

---

## ğŸ“‹ éƒ¨ç½²æµç¨‹æ€»è§ˆ

```
ç¬¬ 1 æ­¥ï¼šæ³¨å†Œ AutoDL è´¦å· â†’ ç¬¬ 2 æ­¥ï¼šç§Ÿç”¨ GPU å®ä¾‹ â†’ ç¬¬ 3 æ­¥ï¼šä¸Šä¼ æ¨¡å‹æ–‡ä»¶
                                                    â†“
ç¬¬ 8 æ­¥ï¼šé…ç½®åç«¯è¿æ¥ â† ç¬¬ 7 æ­¥ï¼šæµ‹è¯• API æ¥å£ â† ç¬¬ 6 æ­¥ï¼šå¯åŠ¨æ¨ç†æœåŠ¡ â† ç¬¬ 5 æ­¥ï¼šå®‰è£…ä¾èµ–
```

---

## ç¬¬ 1 æ­¥ï¼šæ³¨å†Œ AutoDL è´¦å·ï¼ˆ10 åˆ†é’Ÿï¼‰

### 1.1 è®¿é—®å®˜ç½‘

æ‰“å¼€æµè§ˆå™¨ï¼Œè®¿é—®ï¼šhttps://www.autodl.com/

### 1.2 æ³¨å†Œè´¦å·

1. ç‚¹å‡»å³ä¸Šè§’ **"æ³¨å†Œ"** æŒ‰é’®
2. é€‰æ‹©æ³¨å†Œæ–¹å¼ï¼š
   - **æ‰‹æœºå·æ³¨å†Œ**ï¼ˆæ¨èï¼Œæ¥æ”¶éªŒè¯ç ï¼‰
   - é‚®ç®±æ³¨å†Œ
3. å¡«å†™ä¿¡æ¯å¹¶å®ŒæˆéªŒè¯

### 1.3 å®åè®¤è¯

> âš ï¸ **é‡è¦**ï¼šå­¦ç”Ÿè®¤è¯åå¯äº«å—ä¼˜æƒ ä»·æ ¼ï¼

1. ç™»å½•åï¼Œç‚¹å‡»å³ä¸Šè§’ç”¨æˆ·å â†’ **"æ§åˆ¶å°"**
2. å·¦ä¾§èœå•é€‰æ‹© **"å®åè®¤è¯"**
3. ä¸Šä¼ å­¦ç”Ÿè¯ç…§ç‰‡ï¼ˆæ­£é¢ã€æ¸…æ™°ï¼‰
4. å¡«å†™å­¦æ ¡ã€ä¸“ä¸šã€å­¦å·ç­‰ä¿¡æ¯
5. ç­‰å¾…å®¡æ ¸ï¼ˆé€šå¸¸ 1-2 å°æ—¶ï¼‰

### 1.4 å……å€¼

1. ç‚¹å‡» **"å……å€¼"**
2. å»ºè®®é¦–æ¬¡å……å€¼ **50-100 å…ƒ**
3. æ”¯ä»˜æ–¹å¼ï¼šå¾®ä¿¡ã€æ”¯ä»˜å®

> ğŸ’° **è´¹ç”¨å‚è€ƒ**ï¼ˆå­¦ç”Ÿä¼˜æƒ åï¼‰ï¼š
> | GPU å‹å· | åŸä»· | å­¦ç”Ÿä»· | æ¨èåº¦ |
> |----------|------|--------|--------|
> | RTX 4090 24GB | ~3 å…ƒ/å°æ—¶ | ~2 å…ƒ/å°æ—¶ | â­â­â­â­â­ |
> | RTX 3090 24GB | ~2 å…ƒ/å°æ—¶ | ~1.5 å…ƒ/å°æ—¶ | â­â­â­â­ |
> | A100 40GB | ~5 å…ƒ/å°æ—¶ | ~3.5 å…ƒ/å°æ—¶ | â­â­â­ |

---

## ç¬¬ 2 æ­¥ï¼šç§Ÿç”¨ GPU å®ä¾‹ï¼ˆ15 åˆ†é’Ÿï¼‰

### 2.1 åˆ›å»ºå®ä¾‹

1. åœ¨æ§åˆ¶å°ç‚¹å‡» **"åˆ›å»ºå®ä¾‹"**

2. **é€‰æ‹©å®ä¾‹ç±»å‹**ï¼š
   - é€‰æ‹© **"è‡ªå®šä¹‰é•œåƒ"**
   - é•œåƒæœç´¢ï¼š`PyTorch`
   - é€‰æ‹©ç‰ˆæœ¬ï¼š`PyTorch 2.0+` æˆ– `PyTorch 2.1+`
   - CUDA ç‰ˆæœ¬ï¼š`CUDA 11.8` æˆ–æ›´é«˜

3. **é€‰æ‹© GPU å‹å·**ï¼š
   - æ¨èï¼š**RTX 4090 24GB**ï¼ˆæ€§ä»·æ¯”é«˜ï¼Œæ˜¾å­˜å……è¶³ï¼‰
   - å¤‡é€‰ï¼šRTX 3090 24GBï¼ˆæ›´ä¾¿å®œï¼‰

4. **é…ç½® CPU å’Œå†…å­˜**ï¼š
   - CPUï¼š`4 æ ¸`ï¼ˆè¶³å¤Ÿï¼‰
   - å†…å­˜ï¼š`32GB`ï¼ˆæ¨èï¼‰

5. **é…ç½®ç³»ç»Ÿç›˜**ï¼š
   - å®¹é‡ï¼š`100GB`ï¼ˆæ¨¡å‹çº¦ 15GB + ç¯å¢ƒ 20GB + ä½™é‡ï¼‰
   - ç±»å‹ï¼š`SSD`ï¼ˆé»˜è®¤ï¼‰

6. **æ•°æ®ç›˜**ï¼ˆå¯é€‰ï¼‰ï¼š
   - å¦‚éœ€å­˜å‚¨å¤§é‡æ•°æ®å¯æ·»åŠ ï¼Œæš‚æ—¶ä¸éœ€è¦

7. ç‚¹å‡» **"ç«‹å³åˆ›å»º"**

### 2.2 ç­‰å¾…å®ä¾‹å¯åŠ¨

- åˆ›å»ºè¿›åº¦æ¡èµ°å®Œåï¼Œå®ä¾‹çŠ¶æ€å˜ä¸º **"è¿è¡Œä¸­"**
- è®°å½•ä»¥ä¸‹ä¿¡æ¯ï¼š
  - **å®ä¾‹ ID**
  - **å®ä¾‹åç§°**
  - **å…¬ç½‘ IP åœ°å€**
  - **SSH ç«¯å£**
  - **JupyterLab é“¾æ¥**

---

## ç¬¬ 3 æ­¥ï¼šä¸Šä¼ æ¨¡å‹æ–‡ä»¶ï¼ˆ30 åˆ†é’Ÿï¼‰

### æ–¹å¼ä¸€ï¼šä½¿ç”¨ AutoDL æ–‡ä»¶ä¼ è¾“å·¥å…·ï¼ˆæ¨èï¼‰

#### 3.1.1 ä¸‹è½½ä¼ è¾“å·¥å…·

1. åœ¨å®ä¾‹è¯¦æƒ…é¡µï¼Œç‚¹å‡» **"æ–‡ä»¶"** â†’ **"æ–‡ä»¶ä¼ è¾“"**
2. ä¸‹è½½ **AutoDL æ–‡ä»¶ä¼ è¾“å·¥å…·**ï¼ˆWindows ç‰ˆï¼‰
3. è§£å‹å¹¶è¿è¡Œ

#### 3.1.2 é…ç½®è¿æ¥

1. å¡«å†™å®ä¾‹ä¿¡æ¯ï¼š
   - **å®ä¾‹ ID**ï¼šä»æ§åˆ¶å°å¤åˆ¶
   - **ç”¨æˆ·å**ï¼š`root`
   - **å¯†ç **ï¼šåœ¨å®ä¾‹è¯¦æƒ…é¡µç‚¹å‡» **"é‡ç½®å¯†ç "** è·å–

2. ç‚¹å‡» **"è¿æ¥"**

#### 3.1.3 ä¸Šä¼ æ¨¡å‹æ–‡ä»¶

1. å·¦ä¾§æ˜¯æœ¬åœ°æ–‡ä»¶ï¼Œå³ä¾§æ˜¯æœåŠ¡å™¨æ–‡ä»¶
2. åœ¨å³ä¾§å¯¼èˆªåˆ°ï¼š`/root/autodl-tmp/`
3. å°†æœ¬åœ°è®­ç»ƒå¥½çš„æ¨¡å‹æ–‡ä»¶å¤¹æ‹–æ‹½åˆ°å³ä¾§

**æ¨¡å‹æ–‡ä»¶å¤¹ç»“æ„ç¤ºä¾‹**ï¼š
```
dental_qwen_merged/
â”œâ”€â”€ config.json
â”œâ”€â”€ model.safetensors
â”œâ”€â”€ tokenizer.json
â”œâ”€â”€ tokenizer_config.json
â”œâ”€â”€ generation_config.json
â””â”€â”€ adapter_config.json
```

> âš ï¸ **æ³¨æ„**ï¼šå¦‚æœæ¨¡å‹æ–‡ä»¶å¤§äº 2GBï¼Œå»ºè®®ä½¿ç”¨æ–¹å¼äºŒ

---

### æ–¹å¼äºŒï¼šä½¿ç”¨ SCP å‘½ä»¤ä¸Šä¼ 

#### 3.2.1 åœ¨æœ¬åœ°ç”µè„‘æ‰“å¼€ PowerShell

```powershell
# è¿›å…¥æ¨¡å‹æ‰€åœ¨ç›®å½•
cd D:\Project\æ¯•ä¸šè®¾è®¡\data\models\

# ä¸Šä¼ æ¨¡å‹ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®ä¾‹ä¿¡æ¯ï¼‰
scp -P ç«¯å£å· -r dental_qwen_merged root@å®ä¾‹åœ°å€:/root/autodl-tmp/

# ç¤ºä¾‹ï¼š
# scp -P 12345 -r dental_qwen_merged root@connect.autodl.com:/root/autodl-tmp/
```

#### 3.2.2 éªŒè¯ä¸Šä¼ 

åœ¨ AutoDL çš„ JupyterLab ç»ˆç«¯æ‰§è¡Œï¼š
```bash
ls -lh /root/autodl-tmp/dental_qwen_merged/
```

åº”è¯¥çœ‹åˆ°æ¨¡å‹æ–‡ä»¶åˆ—è¡¨ã€‚

---

### æ–¹å¼ä¸‰ï¼šä» HuggingFace/ModelScope ä¸‹è½½ï¼ˆå¦‚æœæ¨¡å‹å·²ä¸Šä¼ ï¼‰

å¦‚æœä½ å·²å°†å¾®è°ƒåçš„æ¨¡å‹ä¸Šä¼ åˆ° ModelScopeï¼š

```bash
cd /root/autodl-tmp

# å®‰è£… ModelScope
pip install modelscope

# ä¸‹è½½æ¨¡å‹
python -c "from modelscope import snapshot_download; snapshot_download('ä½ çš„æ¨¡å‹ ID', cache_dir='./models')"
```

---

## ç¬¬ 4 æ­¥ï¼šå®‰è£…æ¨ç†æ¡†æ¶ä¾èµ–ï¼ˆ15 åˆ†é’Ÿï¼‰

### 4.1 è¿æ¥åˆ° JupyterLab

1. åœ¨å®ä¾‹è¯¦æƒ…é¡µç‚¹å‡» **"JupyterLab"**
2. æµè§ˆå™¨ä¼šè‡ªåŠ¨æ‰“å¼€ JupyterLab ç•Œé¢

### 4.2 æ‰“å¼€ç»ˆç«¯

åœ¨ JupyterLab ä¸­ï¼š
1. ç‚¹å‡»å·¦ä¾§ **"Terminal"** å›¾æ ‡ï¼ˆæˆ– `File` â†’ `New` â†’ `Terminal`ï¼‰
2. è¿›å…¥ç»ˆç«¯ç•Œé¢

### 4.3 å®‰è£… vLLM æ¨ç†æ¡†æ¶

```bash
# å‡çº§ pip
pip install --upgrade pip

# å®‰è£… vLLMï¼ˆæ¨èï¼Œæ€§èƒ½æœ€å¥½ï¼‰
pip install vllm==0.4.0

# æˆ–è€…å®‰è£…æœ€æ–°ç‰ˆæœ¬
# pip install vllm
```

> â±ï¸ **å®‰è£…æ—¶é—´**ï¼šçº¦ 5-10 åˆ†é’Ÿ

### 4.4 éªŒè¯å®‰è£…

```bash
python -c "import vllm; print(vllm.__version__)"
```

çœ‹åˆ°ç‰ˆæœ¬å·è¡¨ç¤ºå®‰è£…æˆåŠŸã€‚

### 4.5 å®‰è£…å…¶ä»–ä¾èµ–ï¼ˆå¯é€‰ï¼‰

```bash
# å¦‚æœéœ€è¦ OpenAI å…¼å®¹ API æ ¼å¼
pip install fastapi uvicorn pydantic

# ç›‘æ§å·¥å…·
pip install psutil
```

---

## ç¬¬ 5 æ­¥ï¼šå¯åŠ¨æ¨ç†æœåŠ¡ï¼ˆ10 åˆ†é’Ÿï¼‰

### 5.1 æµ‹è¯•æ¨¡å‹åŠ è½½

```bash
cd /root/autodl-tmp

# æµ‹è¯•æ¨¡å‹èƒ½å¦æ­£å¸¸åŠ è½½
python -c "
from transformers import AutoModelForCausalLM, AutoTokenizer
import torch

model_path = './dental_qwen_merged'
print('Loading tokenizer...')
tokenizer = AutoTokenizer.from_pretrained(model_path, trust_remote_code=True)
print('Loading model...')
model = AutoModelForCausalLM.from_pretrained(
    model_path,
    torch_dtype=torch.float16,
    device_map='auto',
    trust_remote_code=True
)
print('Model loaded successfully!')
"
```

### 5.2 å¯åŠ¨ vLLM æ¨ç†æœåŠ¡

```bash
# è¿›å…¥æ¨¡å‹ç›®å½•
cd /root/autodl-tmp

# å¯åŠ¨æ¨ç†æœåŠ¡ï¼ˆåå°è¿è¡Œï¼‰
nohup python -m vllm.entrypoints.api_server \
    --model ./dental_qwen_merged \
    --host 0.0.0.0 \
    --port 8080 \
    --served-model-name dental_qwen \
    --max-model-len 2048 \
    --tensor-parallel-size 1 \
    --gpu-memory-utilization 0.9 \
    > vllm.log 2>&1 &

# æŸ¥çœ‹æ—¥å¿—
tail -f vllm.log
```

### 5.3 éªŒè¯æœåŠ¡å¯åŠ¨

```bash
# ç­‰å¾…çœ‹åˆ° "Uvicorn running on http://0.0.0.0:8080"

# æµ‹è¯•æœ¬åœ°è®¿é—®
curl http://localhost:8080/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "ä½ å¥½", "max_tokens": 50}'
```

---

## ç¬¬ 6 æ­¥ï¼šé…ç½®å…¬ç½‘è®¿é—®ï¼ˆ5 åˆ†é’Ÿï¼‰

### 6.1 å¼€æ”¾ç«¯å£

1. åœ¨ AutoDL æ§åˆ¶å°ï¼Œè¿›å…¥å®ä¾‹è¯¦æƒ…é¡µ
2. ç‚¹å‡» **"è‡ªå®šä¹‰æœåŠ¡"** æ ‡ç­¾
3. ç‚¹å‡» **"æ·»åŠ æœåŠ¡"**
4. å¡«å†™ï¼š
   - **æœåŠ¡åç§°**ï¼š`AI æ¨ç†æœåŠ¡`
   - **ç«¯å£**ï¼š`8080`
   - **åè®®**ï¼š`HTTP`
5. ç‚¹å‡» **"ç¡®å®š"**

### 6.2 è·å–å…¬ç½‘åœ°å€

æ·»åŠ æˆåŠŸåï¼Œä¼šæ˜¾ç¤ºå…¬ç½‘è®¿é—® URLï¼š
```
http://å®ä¾‹ IP:éšæœºç«¯å£
```

**ç¤ºä¾‹**ï¼š`http://123.45.67.89:12345`

> âš ï¸ **é‡è¦**ï¼šè®°å½•è¿™ä¸ª URLï¼Œåç»­åç«¯é…ç½®éœ€è¦ç”¨åˆ°ï¼

### 6.3 æµ‹è¯•å…¬ç½‘è®¿é—®

åœ¨æœ¬åœ°ç”µè„‘æµè§ˆå™¨è®¿é—®ï¼š
```
http://å®ä¾‹ IP:éšæœºç«¯å£/generate?prompt=ä½ å¥½&max_tokens=50
```

æˆ–è€…ä½¿ç”¨ curlï¼š
```bash
curl http://å®ä¾‹ IP:éšæœºç«¯å£/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "ç§æ¤ç‰™æœ¯åå¤šä¹…èƒ½åƒé¥­ï¼Ÿ", "max_tokens": 100}'
```

---

## ç¬¬ 7 æ­¥ï¼šæµ‹è¯• API æ¥å£ï¼ˆ10 åˆ†é’Ÿï¼‰

### 7.1 vLLM æ ‡å‡† API æ ¼å¼

**æ¥å£åœ°å€**ï¼š`POST /generate`

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl http://å®ä¾‹ IP:éšæœºç«¯å£/generate \
    -H "Content-Type: application/json" \
    -d '{
        "prompt": "ç§æ¤ç‰™æœ¯åå¤šä¹…èƒ½æ­£å¸¸åƒé¥­ï¼Ÿ",
        "max_tokens": 200,
        "temperature": 0.7
    }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
    "text": ["ä¸€èˆ¬ç§æ¤ç‰™æœ¯å 2-3 ä¸ªæœˆå¯ä»¥æ­£å¸¸å’€åš¼é£Ÿç‰©..."]
}
```

### 7.2 OpenAI å…¼å®¹æ ¼å¼ï¼ˆå¦‚æœå¯ç”¨ï¼‰

**æ¥å£åœ°å€**ï¼š`POST /v1/chat/completions`

**è¯·æ±‚ç¤ºä¾‹**ï¼š
```bash
curl http://å®ä¾‹ IP:éšæœºç«¯å£/v1/chat/completions \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer EMPTY" \
    -d '{
        "model": "dental_qwen",
        "messages": [
            {"role": "system", "content": "ä½ æ˜¯ä¸€åç‰™ç§‘ä¿®å¤ AI åŠ©æ‰‹ã€‚"},
            {"role": "user", "content": "ç§æ¤ç‰™æœ¯åå¤šä¹…èƒ½åƒé¥­ï¼Ÿ"}
        ],
        "max_tokens": 200
    }'
```

**å“åº”ç¤ºä¾‹**ï¼š
```json
{
    "choices": [{
        "message": {
            "content": "ä¸€èˆ¬ç§æ¤ç‰™æœ¯å 2-3 ä¸ªæœˆ..."
        }
    }]
}
```

### 7.3 æµ‹è¯•ç‰™ç§‘ä¸“ä¸šé—®é¢˜

```bash
# æµ‹è¯•é—®é¢˜ 1
curl http://å®ä¾‹ IP:éšæœºç«¯å£/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "æ´»åŠ¨ä¹‰é½¿åˆšæˆ´ä¸Šå¾ˆä¸èˆ’æœï¼Œæ­£å¸¸å—ï¼Ÿ", "max_tokens": 200}'

# æµ‹è¯•é—®é¢˜ 2
curl http://å®ä¾‹ IP:éšæœºç«¯å£/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "çƒ¤ç“·ç‰™èƒ½ç”¨å¤šä¹…ï¼Ÿ", "max_tokens": 200}'

# æµ‹è¯•é—®é¢˜ 3
curl http://å®ä¾‹ IP:éšæœºç«¯å£/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "ç§æ¤ç‰™æœ¯åå‡ºè¡€æ€ä¹ˆåŠï¼Ÿ", "max_tokens": 200}'
```

---

## ç¬¬ 8 æ­¥ï¼šé…ç½®åç«¯è¿æ¥ï¼ˆ5 åˆ†é’Ÿï¼‰

### 8.1 æ›´æ–°åç«¯ `.env` æ–‡ä»¶

åœ¨æœ¬åœ°åç«¯é¡¹ç›®ä¸­ï¼Œç¼–è¾‘ `backend/.env`ï¼š

```env
# AI æœåŠ¡é…ç½®
AI_SERVICE_TYPE=autodl
AI_MAX_TOKENS=512
AI_TEMPERATURE=0.7
AI_TIMEOUT_SECONDS=60

# AutoDL æœåŠ¡å™¨åœ°å€ï¼ˆæ›¿æ¢ä¸ºä½ çš„å®é™…åœ°å€ï¼‰
AUTODL_SERVER_URL=http://123.45.67.89:12345
AUTODL_MODEL_NAME=dental_qwen
AUTODL_API_KEY=
```

### 8.2 é‡å¯æœ¬åœ°åç«¯æœåŠ¡

```bash
cd D:\Project\æ¯•ä¸šè®¾è®¡\backend

# æ¿€æ´»è™šæ‹Ÿç¯å¢ƒ
venv\Scripts\activate

# é‡å¯æœåŠ¡
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

### 8.3 æµ‹è¯•åç«¯å¯¹è¯æ¥å£

```bash
# å…ˆç™»å½•è·å– token
curl http://localhost:8000/api/auth/login \
    -H "Content-Type: application/json" \
    -d '{"username": "admin", "password": "admin123"}'

# ä½¿ç”¨ token æµ‹è¯•å¯¹è¯
curl http://localhost:8000/api/dialogues/ \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer YOUR_TOKEN_HERE" \
    -d '{
        "patient_id": 1,
        "session_id": "test_001",
        "user_message": "ç§æ¤ç‰™æœ¯åå¤šä¹…èƒ½æ­£å¸¸åƒé¥­ï¼Ÿ",
        "message_type": "consultation"
    }'
```

---

## âœ… éƒ¨ç½²å®Œæˆæ£€æŸ¥æ¸…å•

å®Œæˆä»¥ä¸Šæ­¥éª¤åï¼Œè¯·å¯¹ç…§æ£€æŸ¥ï¼š

### ç¯å¢ƒå‡†å¤‡
- [ ] AutoDL è´¦å·å·²æ³¨å†Œå¹¶å®Œæˆå®åè®¤è¯
- [ ] è´¦å·å·²å……å€¼ï¼ˆ50 å…ƒä»¥ä¸Šï¼‰
- [ ] GPU å®ä¾‹å·²åˆ›å»ºå¹¶è¿è¡Œä¸­

### æ¨¡å‹éƒ¨ç½²
- [ ] æ¨¡å‹æ–‡ä»¶å·²ä¸Šä¼ åˆ° AutoDL æœåŠ¡å™¨
- [ ] vLLM æ¨ç†æ¡†æ¶å·²å®‰è£…
- [ ] æ¨¡å‹å¯ä»¥æ­£å¸¸åŠ è½½
- [ ] æ¨ç†æœåŠ¡å·²å¯åŠ¨ï¼ˆç«¯å£ 8080ï¼‰

### ç½‘ç»œé…ç½®
- [ ] è‡ªå®šä¹‰æœåŠ¡å·²æ·»åŠ ï¼ˆç«¯å£ 8080ï¼‰
- [ ] å…¬ç½‘è®¿é—® URL å·²è·å–
- [ ] æœ¬åœ°å¯ä»¥è®¿é—®æ¨ç†æœåŠ¡

### API æµ‹è¯•
- [ ] /generate æ¥å£æµ‹è¯•é€šè¿‡
- [ ] ç‰™ç§‘ä¸“ä¸šé—®é¢˜å›ç­”æ­£å¸¸
- [ ] åç«¯é…ç½®å·²æ›´æ–°
- [ ] åç«¯å¯ä»¥è°ƒç”¨ AutoDL æœåŠ¡

---

## ğŸ†˜ å¸¸è§é—®é¢˜è§£ç­”

### Q1ï¼šå®ä¾‹åˆ›å»ºå¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**ï¼šæ£€æŸ¥ä»¥ä¸‹å‡ ç‚¹ï¼š
1. è´¦å·ä½™é¢æ˜¯å¦å……è¶³
2. æ˜¯å¦å®Œæˆå®åè®¤è¯
3. å°è¯•é€‰æ‹©å…¶ä»–å¯ç”¨åŒºçš„å®ä¾‹

### Q2ï¼šæ¨¡å‹ä¸Šä¼ å¤ªæ…¢æ€ä¹ˆåŠï¼Ÿ

**A**ï¼š
1. ä½¿ç”¨ AutoDL æ–‡ä»¶ä¼ è¾“å·¥å…·ï¼ˆæ¯” SCP å¿«ï¼‰
2. å¦‚æœæ¨¡å‹å¤ªå¤§ï¼Œå¯ä»¥è€ƒè™‘åœ¨ AutoDL ä¸Šé‡æ–°è®­ç»ƒ
3. æˆ–è€…å…ˆå°†æ¨¡å‹å‹ç¼©ï¼š`tar -czf model.tar.gz dental_qwen_merged/`

### Q3ï¼švLLM å®‰è£…å¤±è´¥æ€ä¹ˆåŠï¼Ÿ

**A**ï¼š
```bash
# å°è¯•å®‰è£…æŒ‡å®šç‰ˆæœ¬
pip install vllm==0.4.0

# æˆ–è€…ä½¿ç”¨ Transformers å¯åŠ¨ï¼ˆæ€§èƒ½ç¨å·®ä½†å…¼å®¹æ€§å¥½ï¼‰
pip install transformers accelerate
```

### Q4ï¼šæœåŠ¡å¯åŠ¨åæ— æ³•è®¿é—®æ€ä¹ˆåŠï¼Ÿ

**A**ï¼šæ£€æŸ¥ï¼š
1. æœåŠ¡æ˜¯å¦æ­£å¸¸è¿è¡Œï¼š`ps aux | grep vllm`
2. ç«¯å£æ˜¯å¦å¼€æ”¾ï¼šåœ¨ AutoDL æ§åˆ¶å°æ£€æŸ¥"è‡ªå®šä¹‰æœåŠ¡"
3. é˜²ç«å¢™æ˜¯å¦é˜»æ­¢ï¼šAutoDL é»˜è®¤å¼€æ”¾è‡ªå®šä¹‰æœåŠ¡ç«¯å£

### Q5ï¼šæ¨¡å‹å›å¤ä¹±ç æˆ–é”™è¯¯æ€ä¹ˆåŠï¼Ÿ

**A**ï¼š
1. æ£€æŸ¥æ¨¡å‹æƒé‡æ˜¯å¦å®Œæ•´ä¸Šä¼ 
2. éªŒè¯ tokenizer æ–‡ä»¶æ˜¯å¦å­˜åœ¨
3. å°è¯•é‡æ–°å¯åŠ¨æœåŠ¡
4. æ£€æŸ¥æ˜¾å­˜æ˜¯å¦å……è¶³ï¼š`nvidia-smi`

### Q6ï¼šå¦‚ä½•èŠ‚çœ AutoDL è´¹ç”¨ï¼Ÿ

**A**ï¼š
1. **ä¸ç”¨æ—¶åŠæ—¶å…³æœº**ï¼ˆåœ¨æ§åˆ¶å°ç‚¹å‡»"å…³æœº"ï¼‰
2. å…³æœºååªæ”¶å–å­˜å‚¨è´¹ï¼ˆçº¦ 0.35 å…ƒ/å¤©/100GBï¼‰
3. ä¸‹æ¬¡ä½¿ç”¨æ—¶å¼€æœºï¼Œæ•°æ®ä¸ä¼šä¸¢å¤±
4. ä½¿ç”¨ RTX 4090 è€Œé A100

---

## ğŸ“Š éƒ¨ç½²ç›‘æ§

### æŸ¥çœ‹æœåŠ¡çŠ¶æ€

```bash
# æŸ¥çœ‹ vLLM è¿›ç¨‹
ps aux | grep vllm

# æŸ¥çœ‹æ—¥å¿—
tail -f /root/autodl-tmp/vllm.log

# æŸ¥çœ‹æ˜¾å­˜ä½¿ç”¨
nvidia-smi

# æŸ¥çœ‹ç«¯å£å ç”¨
netstat -tlnp | grep 8080
```

### æ€§èƒ½ç›‘æ§

```bash
# å®‰è£…ç›‘æ§å·¥å…·
pip install gpustat

# å®æ—¶æŸ¥çœ‹ GPU çŠ¶æ€
watch -n 1 gpustat
```

---

## ğŸ“ é‡è¦ä¿¡æ¯è®°å½•è¡¨

éƒ¨ç½²å®Œæˆåï¼Œè¯·è®°å½•ä»¥ä¸‹ä¿¡æ¯ï¼š

| ä¿¡æ¯é¡¹ | å€¼ | å¤‡æ³¨ |
|--------|-----|------|
| AutoDL å®ä¾‹ ID | | |
| å…¬ç½‘ IP åœ°å€ | | |
| æ¨ç†æœåŠ¡ç«¯å£ | | |
| å…¬ç½‘è®¿é—® URL | `http://___:___` | å®Œæ•´ URL |
| æ¨¡å‹è·¯å¾„ | `/root/autodl-tmp/dental_qwen_merged` | |
| vLLM æ—¥å¿—è·¯å¾„ | `/root/autodl-tmp/vllm.log` | |
| éƒ¨ç½²æ—¥æœŸ | | |

---

## ğŸ”„ ä¸‹æ¬¡å¼€æœºæ“ä½œ

å¦‚æœå…³æœºåé‡æ–°å¼€æœºï¼š

```bash
# 1. å¼€æœºåï¼ŒSSH æˆ– JupyterLab è¿æ¥

# 2. å¯åŠ¨æ¨ç†æœåŠ¡
cd /root/autodl-tmp
nohup python -m vllm.entrypoints.api_server \
    --model ./dental_qwen_merged \
    --host 0.0.0.0 \
    --port 8080 \
    --served-model-name dental_qwen \
    --max-model-len 2048 \
    > vllm.log 2>&1 &

# 3. éªŒè¯æœåŠ¡
curl http://localhost:8080/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "æµ‹è¯•", "max_tokens": 50}'
```

---

**æ–‡æ¡£ç‰ˆæœ¬**ï¼šv1.0
**åˆ›å»ºæ—¥æœŸ**ï¼š2026 å¹´ 2 æœˆ 27 æ—¥
**é€‚ç”¨å¯¹è±¡**ï¼šæ¯•ä¸šè®¾è®¡å¼€å‘è€…
