# AutoDL 一键启动脚本使用说明

## 📁 文件位置

**脚本文件**：`D:\Project\毕业设计\data\AI 模型部署\start.sh`

---

## 🚀 使用方法

### 步骤 1：上传脚本到 AutoDL

**方式一：JupyterLab 上传**

1. 打开 AutoDL JupyterLab
2. 在文件浏览器中，右键 → `Upload Files`
3. 选择 `start.sh` 文件
4. 上传到 `/root/autodl-tmp/` 目录

**方式二：SCP 上传**

```bash
# 在本地 PowerShell 执行
scp -P 端口号 start.sh root@实例地址:/root/autodl-tmp/
```

---

### 步骤 2：赋予执行权限

在 JupyterLab 终端执行：

```bash
cd /root/autodl-tmp
chmod +x start.sh
```

---

### 步骤 3：运行脚本

```bash
bash start.sh
```

---

## 📋 脚本功能

### 首次运行

脚本会询问以下信息：

```
╔══════════════════════════════════════════════════════════╗
║     牙科修复 AI 模型 - AutoDL 一键启动配置脚本            ║
╚══════════════════════════════════════════════════════════╝

⚠️  未检测到历史配置，需要进行初始化设置

============================================================
📝 配置 AutoDL 公网访问信息
============================================================

💡 提示：在 AutoDL 控制台 → 实例详情 → 自定义服务 中查看

1. 输入 AutoDL 实例 IP（如：123.45.67.89，可直接回车跳过）: 
2. 输入公网映射端口（如：12345，可直接回车跳过）: 
```

**输入说明**：
- **实例 IP**：AutoDL 实例的公网 IP（可选，可回车跳过）
- **公网映射端口**：在 AutoDL 控制台"自定义服务"中添加的端口（可选）

**如果暂时不输入**：
- 服务会正常启动
- 之后可以在 AutoDL 控制台配置公网访问
- 再次运行脚本时会更新配置

---

### 再次运行（未更换机器）

```
╔══════════════════════════════════════════════════════════╗
║     牙科修复 AI 模型 - AutoDL 一键启动配置脚本            ║
╚══════════════════════════════════════════════════════════╝

📋 检测到历史配置：

SERVER_URL=http://123.45.67.89:12345
PORT=8080
PUBLIC_PORT=12345

============================================================
👉 是否更换了 AutoDL 实例？
============================================================

   更换实例请输入 y，继续使用当前配置直接回车 (y/n): 
```

**直接回车**：使用现有配置启动，不更改任何设置

**输入 y**：重新配置公网地址和端口

---

### 更换机器后运行

```
   更换实例请输入 y，继续使用当前配置直接回车 (y/n): y

✅ 将重新配置公网地址和端口

============================================================
📝 配置 AutoDL 公网访问信息
============================================================

1. 输入 AutoDL 实例 IP（如：123.45.67.89，可直接回车跳过）: 新 IP
2. 输入公网映射端口（如：12345，可直接回车跳过）: 新端口

✅ 配置已保存：
   实例 IP: 新 IP
   公网端口：新端口
   服务地址：http://新 IP:新端口
```

---

## 📊 脚本执行流程

```
1. 读取历史配置（如果有）
   ↓
2. 询问是否更换实例
   ↓
3. 如需更换，重新配置公网信息
   ↓
4. 检查模型文件是否存在
   ↓
5. 检查并安装依赖（vLLM 等）
   ↓
6. 停止旧服务（如果有）
   ↓
7. 显示 GPU 信息
   ↓
8. 启动 vLLM 推理服务
   ↓
9. 等待服务启动并测试
   ↓
10. 显示服务信息和访问地址
   ↓
11. 测试推理功能
   ↓
12. 保存配置
```

---

## 📝 配置保存

脚本会创建配置文件：`.autodl_config`

```bash
# AutoDL AI 服务配置
# 最后更新：2026-02-27 12:00:00
MODEL_PATH=./dental_qwen_merged
PORT=8080
INSTANCE_IP=123.45.67.89
PUBLIC_PORT=12345
SERVER_URL=http://123.45.67.89:12345
LOG_FILE=vllm_inference.log
VLLM_PID=12345
GPU_NAME=NVIDIA GeForce RTX 4090
```

**配置用途**：
- 下次运行时自动读取
- 避免重复输入相同信息
- 记录服务状态（PID、GPU 等）

---

## 🧪 测试命令

脚本会自动执行测试，也可以手动测试：

### 健康检查
```bash
curl http://localhost:8080/health
```

### 推理测试
```bash
curl http://localhost:8080/generate \
    -H "Content-Type: application/json" \
    -d '{"prompt": "种植牙术后多久能吃饭？", "max_tokens": 100}'
```

### 查看日志
```bash
tail -f vllm_inference.log
```

---

## 🆘 常见问题

### Q1：脚本运行报错"Permission denied"

**A**：需要赋予执行权限
```bash
chmod +x start.sh
```

### Q2：模型目录不存在

**A**：确认模型已上传到正确位置
```bash
ls -lh /root/autodl-tmp/
```

如果模型不在，需要重新上传。

### Q3：vLLM 安装失败

**A**：尝试手动安装
```bash
pip install vllm==0.4.0
```

如果还是失败，可以使用 Transformers 版本（参考 `start_inference.py`）。

### Q4：服务启动后无法访问

**A**：检查以下几点：
1. 服务是否运行：`ps aux | grep vllm`
2. 端口是否开放：在 AutoDL 控制台检查"自定义服务"
3. 日志是否有错误：`tail -f vllm_inference.log`

### Q5：如何停止服务

**A**：
```bash
# 方式 1：使用脚本中的 PID
kill $(cat .autodl_config | grep VLLM_PID | cut -d'=' -f2)

# 方式 2：查找进程
ps aux | grep vllm
kill <PID>

# 方式 3：强制停止
pkill -f vllm.entrypoints.api_server
```

### Q6：如何查看配置

**A**：
```bash
cat .autodl_config
```

### Q7：如何清除配置重新设置

**A**：
```bash
rm .autodl_config
bash start.sh
```

---

## 📊 输出示例

```
╔══════════════════════════════════════════════════════════╗
║              🎉 服务启动成功！                            ║
╚══════════════════════════════════════════════════════════╝

📊 服务信息：
   GPU 型号：NVIDIA GeForce RTX 4090
   显存容量：24576 MB
   服务端口：8080
   内网访问：http://localhost:8080

🌐 公网访问：
   服务地址：http://123.45.67.89:12345
   API 接口：http://123.45.67.89:12345/generate

📝 本地后端配置（backend/.env）：
   AI_SERVICE_URL=http://123.45.67.89:12345/generate

📋 常用命令：
   查看日志：tail -f vllm_inference.log
   健康检查：curl http://localhost:8080/health
   测试接口：curl http://localhost:8080/test
   查看进程：ps aux | grep vllm
   停止服务：kill 12345
   重启服务：bash start.sh

============================================================
测试推理功能...
============================================================

测试问题：种植牙术后多久能吃饭？

✅ 推理测试成功！

回答预览：
一般种植牙术后 2-3 个月可以正常咀嚼食物。但具体情况因人而异，
建议您术后 1 周内吃软食，1 个月内避免用手术侧咀嚼硬物...

============================================================
        ✅ 部署完成！服务正在运行中...
============================================================
```

---

## 🔄 完整工作流程

### 首次部署
```
上传模型 → 上传脚本 → 运行脚本 → 输入公网信息 → 服务启动
```

### 日常启动（未更换机器）
```
运行脚本 → 直接回车 → 服务启动（使用原配置）
```

### 更换机器后
```
运行脚本 → 输入 y → 输入新公网信息 → 服务启动（使用新配置）
```

---

## 💡 提示

1. **脚本会自动处理**：
   - 停止旧服务
   - 检查依赖
   - 启动新服务
   - 测试功能

2. **配置保存在**：`.autodl_config`

3. **日志文件**：`vllm_inference.log`

4. **可以随时查看日志**：`tail -f vllm_inference.log`

5. **每次运行都会询问**是否更换实例，方便切换配置

---

**文档版本**：v1.0
**创建日期**：2026 年 2 月 27 日
