#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
è®­ç»ƒé›†æ•°æ®æ ¡å¯¹å·¥å…·
æ£€æŸ¥æ•°æ®é‡å¤æ€§å’Œè´¨é‡
"""

import json
import hashlib
import sys
from datetime import datetime
from collections import Counter

# è®¾ç½®æ ‡å‡†è¾“å‡ºç¼–ç ä¸º UTF-8
sys.stdout.reconfigure(encoding='utf-8')

def load_json(filepath):
    """åŠ è½½ JSON æ–‡ä»¶"""
    with open(filepath, 'r', encoding='utf-8') as f:
        return json.load(f)

def save_json(data, filepath):
    """ä¿å­˜ JSON æ–‡ä»¶"""
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)

def get_data_hash(item):
    """ç”Ÿæˆæ•°æ®çš„å”¯ä¸€å“ˆå¸Œå€¼ï¼ˆåŸºäº input å­—æ®µï¼‰"""
    input_text = item.get('input', '')
    return hashlib.md5(input_text.encode('utf-8')).hexdigest()

def check_duplicates(data):
    """æ£€æŸ¥é‡å¤æ•°æ®"""
    seen_hashes = {}
    duplicates = []
    
    for i, item in enumerate(data):
        data_hash = get_data_hash(item)
        if data_hash in seen_hashes:
            duplicates.append({
                'index': i,
                'input': item.get('input', '')[:50] + '...' if len(item.get('input', '')) > 50 else item.get('input', ''),
                'duplicate_of': seen_hashes[data_hash]
            })
        else:
            seen_hashes[data_hash] = i
    
    return duplicates

def check_quality(data):
    """æ£€æŸ¥æ•°æ®è´¨é‡"""
    issues = []
    
    for i, item in enumerate(data):
        # æ£€æŸ¥å¿…éœ€å­—æ®µ
        if not item.get('instruction'):
            issues.append(f"ç´¢å¼• {i}: ç¼ºå°‘ instruction å­—æ®µ")
        if not item.get('input'):
            issues.append(f"ç´¢å¼• {i}: ç¼ºå°‘ input å­—æ®µ")
        if not item.get('output'):
            issues.append(f"ç´¢å¼• {i}: ç¼ºå°‘ output å­—æ®µ")
        if not item.get('category'):
            issues.append(f"ç´¢å¼• {i}: ç¼ºå°‘ category å­—æ®µ")
        
        # æ£€æŸ¥ output é•¿åº¦
        output = item.get('output', '')
        if len(output) < 50:
            issues.append(f"ç´¢å¼• {i}: output è¿‡çŸ­ ({len(output)} å­—ç¬¦)")
        if len(output) > 3000:
            issues.append(f"ç´¢å¼• {i}: output è¿‡é•¿ ({len(output)} å­—ç¬¦)")
        
        # æ£€æŸ¥ input é•¿åº¦
        input_text = item.get('input', '')
        if len(input_text) < 5:
            issues.append(f"ç´¢å¼• {i}: input è¿‡çŸ­ ({len(input_text)} å­—ç¬¦)")
        if len(input_text) > 200:
            issues.append(f"ç´¢å¼• {i}: input è¿‡é•¿ ({len(input_text)} å­—ç¬¦)")
        
        # æ£€æŸ¥ category æ˜¯å¦åˆæ³•
        valid_categories = ['æœ¯åæŠ¤ç†', 'æœ¯å‰è¯„ä¼°', 'å¸¸è§é—®é¢˜', 'ä¿®å¤ç±»å‹', 'ææ–™é€‰æ‹©', 'å¤è¯Šè§„èŒƒ', 'ç´§æ€¥æƒ…å†µ']
        if item.get('category') not in valid_categories:
            issues.append(f"ç´¢å¼• {i}: category ä¸åˆæ³• - {item.get('category')}")
    
    return issues

def generate_report(data, duplicates, issues):
    """ç”Ÿæˆæ ¡å¯¹æŠ¥å‘Š"""
    # ç»Ÿè®¡ç±»åˆ«åˆ†å¸ƒ
    category_count = Counter(item.get('category', 'æœªçŸ¥') for item in data)
    
    report = f"""# è®­ç»ƒé›†æ•°æ®æ ¡å¯¹æŠ¥å‘Š

## ç”Ÿæˆæ—¶é—´
{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}

## æ•°æ®æ¦‚è§ˆ
- æ€»æ•°æ®é‡ï¼š{len(data)} æ¡
- ç›®æ ‡æ•°æ®é‡ï¼š500 æ¡
- å®Œæˆè¿›åº¦ï¼š{len(data)/500*100:.1f}%

## é‡å¤æ£€æŸ¥
- é‡å¤æ•°æ®ï¼š{len(duplicates)} æ¡
- é‡å¤ç‡ï¼š{len(duplicates)/len(data)*100:.2f}%
- æ£€æŸ¥ç»“æœï¼š{"âœ… æ— é‡å¤" if not duplicates else f"âš ï¸ å‘ç° {len(duplicates)} æ¡é‡å¤"}

{"### é‡å¤è¯¦æƒ…" if duplicates else ""}
"""
    
    if duplicates:
        for dup in duplicates[:20]:
            report += f"- ç´¢å¼• {dup['index']}: \"{dup['input']}\" (é‡å¤äºç´¢å¼• {dup['duplicate_of']})\n"
    
    report += f"""
## æ•°æ®è´¨é‡
- å‘ç°é—®é¢˜ï¼š{len(issues)} ä¸ª
- è´¨é‡çŠ¶æ€ï¼š{"âœ… é€šè¿‡" if not issues else f"âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜"}

{"### é—®é¢˜è¯¦æƒ…" if issues else ""}
"""
    
    if issues:
        for issue in issues[:20]:
            report += f"- {issue}\n"
    
    report += f"""
## ç±»åˆ«åˆ†å¸ƒ

| ç±»åˆ« | æ•°é‡ | å æ¯” |
|------|------|------|
"""
    
    for category, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True):
        percentage = count / len(data) * 100
        report += f"| {category} | {count} æ¡ | {percentage:.1f}% |\n"
    
    total = sum(category_count.values())
    report += f"| **æ€»è®¡** | **{total} æ¡** | **100%** |\n"
    
    report += f"""
## æ•°æ®ç¤ºä¾‹

### ç¤ºä¾‹ 1ï¼ˆç´¢å¼• 0ï¼‰
- **input**: {data[0].get('input', '')}
- **category**: {data[0].get('category', '')}
- **output é•¿åº¦**: {len(data[0].get('output', ''))} å­—ç¬¦

### ç¤ºä¾‹ 2ï¼ˆç´¢å¼• 50ï¼‰
- **input**: {data[50].get('input', '') if len(data) > 50 else 'N/A'}
- **category**: {data[50].get('category', '') if len(data) > 50 else 'N/A'}
- **output é•¿åº¦**: {len(data[50].get('output', '')) if len(data) > 50 else 0} å­—ç¬¦

### ç¤ºä¾‹ 3ï¼ˆç´¢å¼• 99ï¼‰
- **input**: {data[99].get('input', '') if len(data) > 99 else 'N/A'}
- **category**: {data[99].get('category', '') if len(data) > 99 else 'N/A'}
- **output é•¿åº¦**: {len(data[99].get('output', '')) if len(data) > 99 else 0} å­—ç¬¦

## ç»“è®º

"""
    
    if not duplicates and not issues:
        report += "âœ… **æ•°æ®è´¨é‡ä¼˜ç§€ï¼** æ— é‡å¤æ•°æ®ï¼Œæ— è´¨é‡é—®é¢˜ã€‚\n"
    elif not duplicates:
        report += f"âš ï¸ **æ•°æ®è´¨é‡è‰¯å¥½ã€‚** æ— é‡å¤æ•°æ®ï¼Œä½†å­˜åœ¨ {len(issues)} ä¸ªè´¨é‡é—®é¢˜éœ€è¦ä¿®å¤ã€‚\n"
    else:
        report += f"âŒ **æ•°æ®è´¨é‡éœ€æ”¹è¿›ã€‚** å‘ç° {len(duplicates)} æ¡é‡å¤æ•°æ®å’Œ {len(issues)} ä¸ªè´¨é‡é—®é¢˜ã€‚\n"
    
    report += f"""
## ä¸‹ä¸€æ­¥å»ºè®®

1. {"âœ… æ•°æ®æ— é‡å¤ï¼Œå¯ä»¥ç»§ç»­ç”Ÿæˆå‰©ä½™æ•°æ®" if not duplicates else "âŒ å…ˆä¿®å¤é‡å¤æ•°æ®"}
2. {"âœ… æ•°æ®è´¨é‡åˆæ ¼" if not issues else f"âŒ ä¿®å¤ {len(issues)} ä¸ªè´¨é‡é—®é¢˜"}
3. ğŸ“Š ç»§ç»­ç”Ÿæˆå‰©ä½™çš„ {500 - len(data)} æ¡æ•°æ®
4. ğŸ“ ç”Ÿæˆæœ€ç»ˆçš„æ•°æ®é›†è¯´æ˜æ–‡æ¡£

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´ï¼š{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
"""
    
    return report

def main():
    """ä¸»å‡½æ•°"""
    print("=" * 70)
    print("è®­ç»ƒé›†æ•°æ®æ ¡å¯¹å·¥å…·")
    print("=" * 70)
    
    # åŠ è½½æ•°æ®
    print("\n[1/5] åŠ è½½æ•°æ®...")
    data = load_json('D:/Project/æ¯•ä¸šè®¾è®¡/data/train/train_200.json')
    print(f"      æ•°æ®é‡ï¼š{len(data)} æ¡")
    
    # æ£€æŸ¥é‡å¤
    print("\n[2/5] æ£€æŸ¥é‡å¤æ•°æ®...")
    duplicates = check_duplicates(data)
    if duplicates:
        print(f"      âš ï¸ å‘ç° {len(duplicates)} æ¡é‡å¤æ•°æ®")
    else:
        print("      âœ… æ— é‡å¤æ•°æ®")
    
    # æ£€æŸ¥è´¨é‡
    print("\n[3/5] æ£€æŸ¥æ•°æ®è´¨é‡...")
    issues = check_quality(data)
    if issues:
        print(f"      âš ï¸ å‘ç° {len(issues)} ä¸ªé—®é¢˜")
    else:
        print("      âœ… æ•°æ®è´¨é‡åˆæ ¼")
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n[4/5] ç”Ÿæˆæ ¡å¯¹æŠ¥å‘Š...")
    report = generate_report(data, duplicates, issues)
    report_file = 'D:/Project/æ¯•ä¸šè®¾è®¡/data/train/train_200_check_report.md'
    with open(report_file, 'w', encoding='utf-8') as f:
        f.write(report)
    print(f"      æŠ¥å‘Šå·²ä¿å­˜ï¼š{report_file}")
    
    # ä¿å­˜å»é‡åçš„æ•°æ®ï¼ˆå¦‚æœæœ‰é‡å¤ï¼‰
    print("\n[5/5] ä¿å­˜å»é‡åçš„æ•°æ®...")
    if duplicates:
        seen_hashes = set()
        unique_data = []
        for item in data:
            data_hash = get_data_hash(item)
            if data_hash not in seen_hashes:
                seen_hashes.add(data_hash)
                unique_data.append(item)
        
        dedup_file = 'D:/Project/æ¯•ä¸šè®¾è®¡/data/train/train_300_dedup.json'
        save_json(unique_data, dedup_file)
        print(f"      å»é‡åæ•°æ®ï¼š{len(unique_data)} æ¡")
        print(f"      å·²ä¿å­˜ï¼š{dedup_file}")
    else:
        print("      æ— éœ€å»é‡")
    
    # æ‰“å°ç»Ÿè®¡ä¿¡æ¯
    print("\n" + "=" * 70)
    print("ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 70)
    
    from collections import Counter
    category_count = Counter(item.get('category', 'æœªçŸ¥') for item in data)
    print("\nç±»åˆ«åˆ†å¸ƒ:")
    for category, count in sorted(category_count.items(), key=lambda x: x[1], reverse=True):
        percentage = count / len(data) * 100
        print(f"  {category}: {count} æ¡ ({percentage:.1f}%)")
    
    print(f"\næ€»æ•°æ®é‡ï¼š{len(data)} æ¡")
    print(f"ç›®æ ‡æ•°æ®é‡ï¼š500 æ¡")
    print(f"å®Œæˆè¿›åº¦ï¼š{len(data)/500*100:.1f}%")
    print(f"è¿˜éœ€ç”Ÿæˆï¼š{500 - len(data)} æ¡")
    
    print("\n" + "=" * 70)
    if not duplicates and not issues:
        print("âœ… æ ¡å¯¹å®Œæˆï¼æ•°æ®è´¨é‡ä¼˜ç§€ï¼")
    elif not duplicates:
        print(f"âš ï¸ æ ¡å¯¹å®Œæˆï¼æ•°æ®æ— é‡å¤ï¼Œä½†å­˜åœ¨ {len(issues)} ä¸ªè´¨é‡é—®é¢˜ã€‚")
    else:
        print(f"âŒ æ ¡å¯¹å®Œæˆï¼å‘ç° {len(duplicates)} æ¡é‡å¤æ•°æ®å’Œ {len(issues)} ä¸ªè´¨é‡é—®é¢˜ã€‚")
    print("=" * 70)

if __name__ == '__main__':
    main()
